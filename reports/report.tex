\documentclass{kththesis}

% remove this if you are using XeLaTeX or LuaLaTeX
\usepackage[utf8]{inputenc}

% Use natbib abbreviated bibliography style
\usepackage[square,numbers]{natbib}
\bibliographystyle{unsrtnat}

\usepackage{lipsum} % This is just to get some nonsense text in this template, can be safely removed

\title{Sequential User Retention Modelling}
\alttitle{Detta är den svenska översättningen av titeln}
\author{Helder Martins}
\email{helder@kth.se}
\supervisor{Hedvig Kjellström (KTH) and Sahar Asadi (Spotify)}
\examiner{Patric Jensfelt}
\programme{Master in Machine Learning}
\school{School of Computer Science and Communication}
\date{\today}


\begin{document}

% Title page
\flyleaf

\begin{abstract}
  English abstract goes here.
  \lipsum[1-2]
\end{abstract}

\clearpage

\begin{otherlanguage}{swedish}
  \begin{abstract}
    Träutensilierna i ett tryckeri äro ingalunda en faktor där
    trevnadens ordningens och ekonomiens upprätthållande, och dock är
    det icke sällan som sorgliga erfarenheter göras ordningens och
    ekon och miens därmed upprätthållande. Träutensilierna i ett
    tryckeri äro ingalunda en oviktig faktor, för trevnadens
    ordningens och och dock är det icke sällan.
  \end{abstract}
\end{otherlanguage}

\cleardoublepage

\tableofcontents


% This is where the actual contents of the thesis starts
\mainmatter


\chapter{Introduction}

    Service providers, especially those that operates on the mobile market, have experienced a rapid increase in their user base in the last few years. However, the number of companies in each market increased in a similar fashion, and maintaining your current users within your service grew in importance since the process of acquiring new users is costly and difficult to execute properly. One of the important steps towards that goal is to predict accurately what is the chance of a user leaving the service provider at any given time with the intent of acting before it happens, a problem which is called \emph{churn prediction}. Several classical techniques for predicting churn like Decision Trees and Logistic Regression have been used on recent work, however most of them make use of user behaviour data at a single point in time, normally the most recent one when the dataset was created. 
    
    Intuitively one can think that latent factors hidden in the temporal axis of the user behaviour data could yield a better prediction accuracy when comparing to a model which leverage a single and static point in time. For instance, a user that is gradually reducing its consumption of the service over time can be easily thought of a prospect churner. While this intuition is trivial to come up with, we are also interested in learning strong correlations between temporal aspects of the data and the churn rate which are not as clear to the eye. Our hypothesis is that making use of the properties hidden on user behaviour data over time, a churn rate predictor could improve its accuracy greatly when compared to methods which are static on time.
       
	\subsection{Music as a service}
	
	TODO: paragraph / plots about the state the music industry is in today    
        
    
	\subsection{Spotify}
	
	TODO: paragraph introducing the company and its goals (activation problem, high rate of churn for new users)   
    
    The user data and the required computational resources shall be provided by Spotify AB, a well known music streaming service, which joined this project in a tutoring partnership with the student and the university. Creating a suitable dataset for training our proposed models is also part of the project, and shall be done by first exploring the data at our disposal and identifying the features that highly correlates with churn. An example of what this dataset may contain is the user listening habits, usage patterns, user profile, and so on.    
    
	\subsection{Churn prediction}

	TODO: add churn prediction focused on Spotify
	
	\subsection{User retention} 

	TODO: add user retention info on Spotify	

    A churn rate predictor which can identify possible churners accurately is just a trigger on the user retention process that can span several different stages. One of these stages is to identify what actions can be taken by the service provider as to avoid the user abandoning the service. An important problem to solve beforehand is to identify which features of the data have a strong statistical correlation with the churn rate. With that information, the providers could for example set up automated actions as to influence the value on these features. Learning which are the most important features is also of relevance for the task of choosing what data to use for training the predictor models, since commonly service providers have a vast amount of data about the user but only a fraction of that is of importance for predicting churn: training models with a full dataset will commonly introduce error on the system and take a large amount of computing resources to train.
	
	\subsection{Goals}	
	
	TODO: review with supervisor
	
The goal of this project will be to research different models for churn prediction that can make use of the temporal aspect of user behaviour data at its fullest. Our hypothesis is that latent factors hidden on usage patterns may increase the accuracy of state-of-art predictors which considers only the state of the data at a single point in time. We shall experiment on different models that are known to perform well on time series data and compare their accuracy using different evaluation methods. 

Detecting possible churners, while important, does not improve user retention without an associated action performed by the service provider. To derive insights on what can done to improve this metric, a deep data exploration and feature analysis is also a goal of this project. Features shall be correlated to their influence on the churn rate, and feature selection techniques shall be researched and implemented in an attempt to reduce bias on the churn classifiers.
	
	\subsection{Ethical considerations}   
    
	TODO: Is user data anonymous? Is it relevant to add this section?

\subsection{Research Question}
        
    TODO: rewrite    
        
	Can latent factors hidden on user behaviour data improve the accuracy of a churn predictor model when compared to the ones which does not leverage this property? Can techniques proven to be successful for time series prediction on different domains be used interchangeably for prediction of churn rate? What feature selection methods can most successfully extract the correlations between the feature value and churn rate? Can we reasonably interpret what was learnt by our predictor models as to allow the service provider to create actions to keep user retention level high? Can we identify different types of users which exerts an influence on the churn rate of the service?


\chapter{Background}

\subsection{Definitions}

\newtheorem{definition}{Definition}

\begin{definition}
A \emph{session} is defined as the time period the user is engaged into the application, be it to stream music or to navigate through the available content. A session starts when a user interaction trigger is captured (eg. a button click), and the session ends when no such trigger is captured and no continuous activity is being performed (eg. listening to a song) for at least 15 minutes.
\end{definition}

The session is the basic measurement of activity of the user on the service. Users are considered \emph{active} if they are currently on a session, and \emph{inactive} otherwise. (TODO Check Sahar)

\begin{definition}
A user is defined to have \emph{churned} if no session of his was registered in the last 30 days.
\end{definition}

Note that this definition is not concerned whether the user is a paying customer or not, but only if he is actually making use of the service. For example, a user may be subscribed to a Premium paid account and still be considered to have churned if no activity was registered in the last 30 days. However, it should be noted that empirical observations by the service provider suggest that there is a significant behavioural difference between the two classes of users that will be taken into consideration when the experiments are performed. (TODO Check Sahar)

\subsection{Feature Selection}

TODO: add feature selection techniques (Information gain, L1-norm, Recursive Feature Elimination, Variance Threshold...)

\subsection{Predictor Models}

TODO: add models (Decision Trees, Logistic Regression, Random Forests, LSTMs, CNNs...)

\subsection{Evaluation Metrics}

\subsubsection{Confusion Matrix}

A \emph{confusion matrix} (also called contingency table) is a table layout representing the performance of a classifier's output, judging by its predictions against the actual true values. In a binary classification problem, the confusion matrix is a 2 x 2 table where commonly the rows represent the true labels while the columns the predicted classes. Each cell contains a count of how many samples were classified on that category, and the values in the diagonal represent the correctly classified samples (if the features are ordered). Table (TODO: Add table) depicts a confusion matrix for a binary classifier.

The confusion matrix is an excellent visualization tool to estimate the performance of a model. The values that should be maximized, the \emph{true positives} (TP) and \emph{true negatives} (TN), represent the samples that were correctly labelled as possessing the feature of interest or not, respectively. On the other hand, the \emph{false positives} (FP) and \emph{false negatives} (FN) are the misclassified samples where the algorithm predicted that the feature was present while in truth it was not and vice-versa. In this work, the positive class will always represent a churning user, and it follows that the negative class represents the non-churners.

\subsubsection{Classification Accuracy}

Several different metrics can be derived from the confusion matrix table. The \emph{classification accuracy} (CA) of a model is a common metric that corresponds to the fraction of the correctly classified samples on the test set, and can be calculated as follows:

\begin{equation}
CA = \frac{TP + TN}{TP + TN + FP + FN} 
\end{equation}

While trivial to understand, this metric may lead to erroneous conclusions when class imbalance is present in the test set, which is a common occurrence on the churn prediction domain. For example, if 9 out of 10 users of a dataset are non-churners, any classifier that simply outputs a negative class for all samples will result in an accuracy of 90\%, however its ability of detecting churners is non-existent. For a service provider, detecting churn cases is always more important than detecting the loyal users, and this metric by itself cannot represent this goal. (TODO Add ref? Hassouna 2015)

\subsubsection{Precision, Recall, Fall-out and False Alarm}

To address the class imbalance problem of the classification accuracy, others metrics are also commonly used. The \emph{positive predictive value} (PPV, also known as precision) is the proportion of the samples labelled as positive which are true positives, and describes the performance of the algorithm. The \emph{true positive rate} (TPR, also called sensitivity and recall) of a model corresponds to the number of correctly predicted positive samples divided by all positive samples. \emph{True negative rate} (TNR, also called specificity and fall-out) is the number of correctly predicted negatives divided by all true negatives. The \emph{false positive rate} (FPR, also called false alarm ratio) is the probability of receiving a false positive as output of an experiment, and is calculated by dividing the number of false positives by the total number of positive samples.

\begin{equation}
PPV = \frac{TP}{TP + FP}
\end{equation}

\begin{equation}
TPR = \frac{TP}{TP + FN}
\end{equation}

\begin{equation}
TNR = \frac{TN}{TN + FP}
\end{equation}

\begin{equation}
FPR = \frac{FP}{TN + FP} = 1 - TNR
\end{equation}

Depending on the distribution of classes of the dataset, it is often difficult (although desirable) to maximize both metrics at the same time. A compromise must be reached that achieves the best trade-off between the two, which is commonly a business decision. For a music streaming service like Spotify, maximizing sensitivity is preferred due to the costs associated with a churning user, however a reasonable specificity is also a metric that should be strived for. (TODO Check with Sahar)

\subsubsection{Receiver Operating Characteristic}

The \emph{receiver operating characteristic} (ROC) is a visualization tool that plots the relationship between the true positive rate (commonly the y-axis) and the false positive rate (the x-axis) of a binary classifier system. The curve is drawn by selecting different parameters of a model or levels of threshold for the decision boundary between the positive and negative classes. For example, when the output of a classifier is a probability value (like in logistic regression), different thresholds can be chosen to decide whether a user is a churner or not, depending if the goal is to minimize FPR or maximize TPR. An example of a ROC curve can be seen in Figure (TODO Add figure)

A good classifier would score values close to the upper-left corner of the plot, where the point (0,1) represents a perfect classifier with 100\% TPR and 0\% FPR. On the other hand, an algorithm that outputs a curve alongside the diagonal where TPR and FPR are almost the same at different threshold levels can be considered close to a random guess, like the flip of a coin. A classifier would underperform if its scores are closer to the bottom-right corner of the plot, however this result can always be mirrored by updating the model to simply invert the positive and negative labels of the classified samples.

ROC curves can be used to compare the performance of different models by measuring the \emph{area under the curve} (AUC) of its plotted scores, which ranges from 0.0 to 1.0. The greater this area, the better the algorithm is to find a specific feature. Moreover, models with an area close to 0.5 can be assumed to perform not much better than random guess, since this is the total area under the diagonal line.

TODO: Add eval methods (F-score, Lift chart, Top Decile Lift (TDL)...)

\chapter{Related Work}

\section{Churn Prediction}

\section{Sequential Modeling}

\section{Evaluation Metrics}

\textbf{Pudipeddi, Akoglu and Tong} \citep{Pudipeddi2014} In "User Churn in Focused Question Answering Sites: Characterization and Prediction", Q\&A sites like Stack Overflow were the focus of a study on user behaviour characterization and churn rate prediction. An extensive data exploration was made as to correlate features to the chance of a user leaving a service, and with those insights classical modelling techniques were used, where the best performing one was a decision tree. The approach used for extracting and categorizing features (temporal, frequency, gratitude, etc) and the insights that follow the study (like the importance of temporal features for predicting churn) is of high value and can be mapped to concepts on a different domain like a music streaming service with minor modifications.

\textbf{Wangperawong, Brun, Laudy and Pavasuthipaisit} \citep{Wangperawong2016} In "Churn analysis using deep convolutional neural networks and autoencoders" users were represented as 2-dimensional images where columns are tracked features and rows are days. The intuition behind this approach is that by using similar techniques successfully applied on the Image Recognition domain, a similar positive result for the prediction of the churn rate could also be achieved. Two different Convolutional Neural Network models were used, and both outperformed a baseline Decision Tree model. An autoencoder was also used as to discover which features influenced churn rate the most, and suggestions where made as to how improve the retention of users on the service.

\textbf{Tax and Verenich} \citep{Tax2016} In "Predictive Business Process Monitoring with LSTM Neural Networks" a technique was presented as to predict the next event and its timestamp on a running case of a business process (a help desk process, for example). The problem definition was formally explained, and three different LSTM architectures were experimented on. With these architectures, three problems were tackled: estimating the next activity and its timestamp, all the remaining activities in a use case and the remaining time of a process. This technique could be used for churn prediction by interpreting the user interaction with the service as actions, and "churn" could be an event that may or may not exist in the process chain.

\textbf{Runge et al.} \citep{Runge2014} In "Churn prediction for high-value players in casual social games", players responsible for generating the most profit on two casual social games were the focus of a study on churn analysis and prediction. Formal definitions for active players and churning were made, and the problem was defined as a binary classification task where users were labelled as leaving the service or not in the following week of when the models were trained. Four different models were then trained, and a neural network classifier obtained the best area under the curve (AUC) score, with logistic regression as a close second. An attempt was made as to include temporal data in the neural net by enhancing it with features learned with a hidden Markov model (HMM), however the accuracy was decreased due to parameter overfitting. The formal definitions of "churn" and "activity" can be applied to a music streaming service in a similar way, as the evaluation of performance using a series of receiver operating characteristic (ROC) curves. A detailed A/B test with real users was also performed, but a similar approach falls out of the scope of this project.

\textbf{Dror et al.} \citep{Dror2012} In "Churn prediction in new users of Yahoo! answers", an explorative study was made on the Yahoo! answers website as to discover an efficient churn predictor model and also the features that correlates with the user leaving the service, however differently from other works this paper focused on new users with less than a week of activity on the service. Features were grouped into Question, Answer and Gratification categories, and were used for training several different classifiers. For this dataset, random forests performed the best with logistic regression once again a close second. Features were also ordered by the amount of information gain that they provide, and the number of questions and answers are the top features on that regard (inversely correlating with churn), followed by the period of time the user is active and gratification features for answers given and questions made. Similarly to \citep{Pudipeddi2014}, the features exploration section could be mapped to a music streaming service in a similar way (eg. question/answers are sessions, gratitude is the user explicit feedback on recommended content), and the evaluation methods with ROC curves and information gain tables are also of interest. 

\textbf{Hassouna et al.} \citep{Hassouna2015} In "Customer Churn in Mobile Markets: A Comparison of Techniques", two popular models for predicting user churn were empirically compared: decision trees and logistic regression. By making use of the dataset provided by a mobile operator, two models were created by independently training and selecting their best performing versions. Evaluation was executed by comparing the AUC of their ROC curves, as also their Lift score and overall accuracy. The conclusion is that decision trees consistently perform better when compared to logistic regression models, and thus should be a preferred choice.

\textbf{Lu et al.} \citep{Lu2014} In "A Customer Churn Prediction Model in Telecom Industry Using Boosting", churn classification was performed on users of a telecom provider in a rather unique way. The Gentle AdaBoost boosting algorithm was used alongside a logistic regression base learner as to train a model to do the separation between the churning and non-churning classes. However, one further step was performed where the users were split into two clusters based on the weights assigned by the boosting algorithm. One of the clusters was identified to have a considerably larger churn rate than the other, and thus another logistic model was trained using the clusters as labels, and its performance evaluated using ROC curves. The idea behind this approach is to use a model to mark users who have a high risk of leaving the service (and be the focus of user retention actions), instead of labelling them as churners and non-churners directly.

\textbf{Khan et al.} \citep{Khan2015} In "Behavioral Modeling for Churn Prediction: Early Indicators and Accurate Predictors of Custom Defection and Loyalty", billions of call detail records from a mobile phone operator was the focus of a churn prediction study and feature analysis. The initial data set was filtered to the calls made by 100.000 subscribers during a 6 month period. A brute-force approach to feature engineering was then performed to create 12.914 out of the initial 10 features by combining every feature from each of the manually split 8 different groups. Feature selection is then performed in two distinct ways: first, an individual Student's t-test score is computed for each individual feature to evaluate how well it can differentiate between the churners and non-churners sets. Second, a tree-based method was used as to estimate the the accuracy of a joint classifier by adding features one at a time. Features are then ordered by their statistical correlation with churn, and the top 100 features were selected to train several different classifiers. Evaluation was performed mainly by comparing the AUC of each model, where AdaBoost using a decision tree classifier performed the best, followed closely by a logistic regression model.

\textbf{Burez and Van den Poel} \citep{Burez2009} In "Handling class imbalance in customer churn prediction", a recurrent problem on data sets used for churn prediction has taken center stage: the uneven distribution between the churning and non-churning classes. It is a common scenario for the number of non-churners to heavily outweigh the number of churning samples on real data sets, and since the main interest of any classifier is the ability to spot this rare class appropriate evaluation methods should be considered. This paper praises the use of AUC and Lift as suitable metrics for model comparison while detailing several techniques used in the field. The performance boost estimated to be received by using a cost-sensitive learning algorithm (where false negatives are assigned a greater cost than false positives) is also evaluated, and it has taken the form of a weighted random forest model which was compared to other classical baseline models like logistic regression and random forests. Under-sampling, where fewer samples from the majority class are incorporated in the training data as to artificially change the distribution between the labels, is proved to significantly improve the performance of the underlying models, however the exact ratio between churners and non-churners is confirmed to be case-dependant, not necessarily being the even distribution the perfect choice. Another contribution of notice is the use of a 5x2 cross-validation technique to train the models, and the use of a formal F-test for judging whether two algorithms are statistically different or not.

\textbf{Ballings and Van den Poel} \citep{Ballings2012} In "Customer event history for churn prediction: How long is long enough?", this study investigates a common but under-researched property of customer behaviour data sets, which is the time dimension of the data. More specifically, this paper strives to answer how far in the user history models must be trained on as to achieve the best trade-off between accuracy and computational burden. The experiment consisted on training three different models (logistic regression, decision trees with and without bagging) on a newspaper data set consisting of 16 years of user history. The models were evaluated for their performance by training with data ranging on this interval with a 1-year gap between each measurement. It has been concluded that  after year 5 no gain in performance (measured by AUC) is statistically relevant enough to warrant the increase in computational power needed for the training. However, the researchers also question whether this result can be extended for other domains or not, leaving that for future work.

\textbf{Borbora, Hsu and Williams} \citep{Borbora2011} In "Churn prediction in MMORPGs using player motivation theories and an ensemble approach", the activity log of a subscription-based multiplayer online game was the source of an experiment focused on comparing two different approaches for predicting the users with a higher tendency to leave the service. One was a classical theory-driven approach where an hypothesis is established that the rate of progress on achievement-oriented features is higher on non-churning population when compared to the churning population. The other was a data-driven approach where a larger set of features was utilized without any specific theory on what correlates to churn rate. For the modelling, an ensemble method was used with several different classifiers, where the choice of model was made based on whether the cluster of the data set (found with K-means) that will be used to train the classifier has a significant proportion of churners or not. Even though the performance of the data-driven model was superior, the difference was negligible when taking into consideration the complexity of the models and also its interpretability. Moreover, if marketing resources are constrained the theory-driven model was considerably superior for the first 40\% of users on the lift chart. If though the authors praises the use of model based on theories of the player motivations, since no statistical test to prove or disprove their null hypothesis, it is unclear to the reader the real difference between the approaches, seemingly they only differ on the subset of features utilized for training, which maybe could be done by a feature selection algorithm instead. 

\textbf{Zhang et al.} \citep{Zhang2013} In "Understanding user behavior in Spotify", a deep study on user behaviour was performed on a massive dataset of both mobile and desktop versions of Spotify's application. Music streaming services are as of today a quite under-researched area, even though there is a prominent feature that makes it significantly different from other more researched and similar areas like video streaming, which would be the absence of the constant attention factor that video demands. This paper aims to fill that gap by analysing patterns of usage of Spotify's Premium subscribers on features like session and playback arrival patterns, user behaviour on single and multiple devices and favourite times of day for streaming. The main contributions of the study can be summarized as follows: First, daily patterns can be observed on features like session arrival, playback arrivals and session length. Second, there is a high probability of users to continue on the same device for consecutive sessions. Third, users have their unique times of day when they prefer to stream music on the platform. Fourth, a session length can be used as a good indicator of the next session length and also downtime.

\textbf{Längkvist et al.} \citep{Langkvist2014} In "A review of unsupervised feature learning and deep learning for time-series modeling", an overview of the challenges on creating models that make use of the time component on data sets are presented to the reader. Also, since hand-crafted features are generally domain-specific and difficult to create, a review of the current research on unsupervised feature learning applied for time-series data is the focus of this paper. From the challenges, it is worth of mention the uncertainty that there is enough information to understand the underlying process, its non-stationary characteristics like mean, variance and frequency, and its common high dimensionality and noise. The right representation is deemed then crucial for any model to be successful in its goal. Several different techniques currently being used for unsupervised feature learning are then presented in details to the reader, where it is worth of quick mention the conditional Restricted Boltzmann Machine (cRBM), Recurrent Neural Networks (RNN, with is Long Short-Term Memory extension), the Gated RBM, the Time-Delay Neural Networks, and the Space-Time Deep Belief Network. A comparison between models regarding their memory capacity and usual input size is then made, and even though the RNN seems to be a superior choice by numbers only, the author later argues that the best model is highly dependent on the data being used. Finally, several classical time-series problems are reviewed alongside the best models currently being used for each domain.

\textbf{Gur Ali and Ariturk} \citep{GurAli2014} In "Dynamic churn prediction framework with more effective use of rare event data: The case of private banking", the researchers propose a new data set generation framework that can better leverage the temporal aspect of user behaviour data for churn prediction models. It is typical on current research for the data sets used to train models to summarize the user features by taking a single point in time, normally the most recent one available. The hypothesis being tested is that by boosting the data with features on different time periods instead of only the last one, a significant performance gain can be achieved. The main framework of this study is called Multiple Period Training Data (MPTD), which basically consists of aggregating to each user their features at each predefined time step along the time range of the data set, alongside their churn labels at each point in time and also environment variables which varies through time but are common for all users. This framework was tested against the classical Single Period Training Data described above, demonstrating a significant improvement (by \emph{p-value} comparison) on AUC and TDL for both logistic regression and decision tree models for predicting if the user is going to churn on the next test period or nor. Another factor tested was whether the use of balanced data through an oversampling technique called SMOTE (Synthetic minority oversampling technique) could improve the performance of the models, however no significant change could be found. The last experiment was focused on predicting churn several periods on the future, and for that a common survival analysis method called Cox regression was used as a benchmark for comparison against logistic regression models trained on MPTD. It was empirically concluded that using several independently trained binary classifiers, each trained on a different parameter to the "churn within $\delta$ periods" (W$\delta$C) feature, a significant performance gain can be achieved when comparing their respective AUC and TDL.

\textbf{Anand, Kazmi and Malhotra} \citep{Auon2015} In "Deep Temporal Features to Predict Repeat Buyers", a new method is presented for the task of predicting which buyers will return to the store after acquiring a product on sale. Current models commonly use aggregate level or window-based features, neglecting the wealth of information present on the basket-level transactions history. The proposed method involves training a Mixture of Experts (ME) between two types of models: Quantile Regression (QR) for the aggregated features and Long Short-term Memory classifier over the temporal features of the user. Aggregate level features are computed over the entire transaction history of each customer. Some of these features are grouped into non-overlapping windows which are used as independent attributes for the aggregate level model and as a time-series in the temporal model. Both QR and LSTM models are then independently trained with a subset of these features, while also fine tuning the parameters of each through a grid-search tested on a validation set. It was empirically shown that a ME between these two models can reach a significant mean-square error improvement when comparing to any of the independent models.

\chapter{Methods}

\lipsum

\chapter{Results}

\lipsum

\chapter{Conclusions and Future Work}

\lipsum[5]

\bibliography{references}

\appendix

\chapter{Unnecessary Appended Material}

\end{document}
