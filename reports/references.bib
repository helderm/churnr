@Article{einstein2016,
  author = 	 {Einstein, Albert},
  title = 	 {On the Relative Value of Relatives},
  journal = 	 {J. Irreproducible Results},
  year = 	 {2016},
  volume = 	 {17},
  pages = 	 {4711--4721}
}

@InProceedings{heisenberg2015,
  author = 	 {Heisenberg, Werner and Dirac, Paul},
  title = 	 {To be or not to be},
  booktitle =    {Proceedings of the Uncertain Society Annual Meeting},
  year = 	 {2015},
  editor = 	 {Schr√∂dinger, Erwin},
  pages =	 {21--22}
}

 @article{Pudipeddi2014,
 author = {Pudipeddi, Jagat and Akoglu, Leman and Tong, Hanghang},
 file = {:home/helder/Downloads/p469-akoglu.pdf:pdf},
 isbn = {9781450327459},
 keywords = {a sites,churn prediction,feature extraction,q,user churn},
 pages = {469--474},
 title = {{User Churn in Focused Question Answering Sites: Characterizations and Prediction}},
 year = {2014}
 }

@article{Wangperawong2016,
 abstract = {Customer temporal behavioral data was represented as images in order to perform churn prediction by leveraging deep learning architectures prominent in image classification. Supervised  learning was performed on labeled data of over 6 million customers using deep convolutional neural networks, which achieved an AUC of 0.743 on the test dataset using no more than 12 temporal        features for each customer. Unsupervised learning was conducted using autoencoders to better understand the reasons for customer churn. Images that maximally activate the hidden units of an         autoencoder trained with churned customers reveal ample opportunities for action to be taken to prevent churn among strong data, no voice users.},
 archivePrefix = {arXiv},
 arxivId = {1604.05377},
 author = {Wangperawong, Artit and Brun, Cyrille and Laudy, Dr. Olav and Pavasuthipaisit, Rujikorn},
 eprint = {1604.05377},
 keywords = {1,2,3,big data,churn and take,churn prediction,cnns,deep learning,deep learning by convolutional,has demonstrated superior performance,images,in many image processing,in order to        leverage,it,machine learning,neural networks,pro-active measures to prevent,specifically,such advances to predict,tasks,telecommunications,we construct a 2-,we represent customers as},
 pages = {1--6},
 title = {{Churn analysis using deep convolutional neural networks and autoencoders}},
 year = {2016}
 }

 @article{Tax2016,
 abstract = {Predictive business process monitoring methods exploit logs of completed cases of a process in order to make predictions about running cases thereof. Existing methods in this space are  tailor-made for specific prediction tasks. Moreover, their relative accuracy is highly sensitive to the dataset at hand, thus requiring users to engage in trial-and-error and tuning when applying   them in a specific setting. This paper investigates Long Short-Term Memory (LSTM) neural networks as an approach to build consistently accurate models for a wide range of predictive process         monitoring tasks. First, we show that LSTMs outperform existing techniques to predict the next event of a running case and its timestamp. Next, we show how to use models for predicting the next     task in order to predict the full continuation of a running case. Finally, we apply the same approach to predict the remaining time, and show that this approach outperforms existing tailor-made     methods.},
 archivePrefix = {arXiv},
 arxivId = {1612.02130},
 author = {Tax, Niek and Verenich, Ilya and {La Rosa}, Marcello and Dumas, Marlon},
 eprint = {1612.02130},
 title = {{Predictive Business Process Monitoring with LSTM Neural Networks}},
 url = {http://arxiv.org/abs/1612.02130},
 year = {2016}
 }
 
@article{Runge2014,
 abstract = {Predicting when players will leave a game creates a unique opportunity to increase players' lifetime and revenue contribution. Players can be incentivized to stay, strategically cross-  linked to other games in the company's portfolio or, as a last resort, be passed on to other companies through in-game advertisement. This paper focuses on predicting churn for highvalue players    of casual social games and attempts to assess the business impact that can be derived from a predictive churn model. We compare the prediction performance of four common classification algorithms   over two casual social games, each with millions of players. Furthermore, we implement a hidden Markov model to explicitly address temporal dynamics. We find that a neural network achieves the      best prediction performance in terms of area under curve (AUC). In addition, to assess the business value of churn prediction, we design and implement an A/B test on one of the games, using free    in-game currency as an incentive to retain players. Test results indicate that contacting players shortly before the predicted churn event substantially improves the effectiveness of communication  with players. They further show that giving out free in-game currency does not significantly impact the churn rate or monetization of players. This suggests that players can only be retained by     remarkably changing their gameplay experience ahead of the churn event and that cross-linking may be the more effective measure to deal with churning players.},
 author = {Runge, Julian and Gao, Peng and Garcin, Florent and Faltings, Boi},
 doi = {10.1109/CIG.2014.6932875},
 isbn = {9781479935468},
 issn = {23254289},
 journal = {IEEE Conference on Computatonal Intelligence and Games, CIG},
 keywords = {A/B evaluation,churn prediction,freemium,hidden Markov model,neural networks,social casual games},
 title = {{Churn prediction for high-value players in casual social games}},
 year = {2014}
 }
 
  @article{Dror2012,
 author = {Dror, Gideon and Pelleg, Dan and Rokhlenko, Oleg and Szpektor, Idan},
 isbn = {9781450312301},
 journal = {Proceedings of the 21st International Conference on World Wide Web},
 keywords = {churn prediction,community question answering,online user},
 pages = {829--834},
 title = {{Churn prediction in new users of Yahoo! answers}},
 year = {2012}
 }

@article{Hassouna2015,
 author = {Hassouna, Mohammed and Tarhini, Ali and Elyas, Tariq and Aboutrab, Mohammad Saeed and Kingdom, United and Kingdom, United and Arabia, Saudi},
 doi = {10.5539/ibr.v8n6p224},
 file = {:home/helder/Downloads/1607.07792.pdf:pdf},
 keywords = {customer churn,customer relationship management,data mining,mobile market},
 number = {6},
 pages = {224--237},
 title = {{Customer Churn in Mobile Markets: A Comparison of Techniques}},
 volume = {8},
 year = {2015}
 }

 @article{Lu2014,
 author = {Lu, Ning and Lin, Hua and Lu, Jie and Zhang, Guangquan},
 doi = {10.1109/TII.2012.2224355},
 issn = {15513203},
 journal = {IEEE Transactions on Industrial Informatics},
 keywords = {Boosting,Telecommunication,churn prediction,customer relationship management,digital marketing,logistic regression},
 number = {2},
 pages = {1659--1665},
 title = {{A customer churn prediction model in telecom industry using boosting}},
 volume = {10},
 year = {2014}
 }
 
  @article{Khan2015,
 abstract = {Churn prediction, or the task of identifying customers who are likely to discontinue use of a service, is an important and lucrative concern of firms in many different industries. As    these firms collect an increasing amount of large-scale, heterogeneous data on the characteristics and behaviors of customers, new methods become possible for predicting churn. In this paper, we    present a unified analytic framework for detecting the early warning signs of churn, and assigning a "Churn Score" to each customer that indicates the likelihood that the particular individual      will churn within a predefined amount of time. This framework employs a brute force approach to feature engineering, then winnows the set of relevant attributes via feature selection, before        feeding the final feature-set into a suite of supervised learning algorithms. Using several terabytes of data from a large mobile phone network, our method identifies several intuitive - and a few  surprising - early warning signs of churn, and our best model predicts whether a subscriber will churn with 89.4{\%} accuracy.},
 author = {Khan, Muhammad Raza and Manoj, Joshua and Singh, Anikate and Blumenstock, Joshua},
 doi = {10.1109/BigDataCongress.2015.107},
 isbn = {9781467372787},
 journal = {Proceedings - 2015 IEEE International Congress on Big Data, BigData Congress 2015},
 keywords = {Churn,call detail records,data science,machine learning,supervised learning},
 pages = {677--680},
 title = {{Behavioral Modeling for Churn Prediction: Early Indicators and Accurate Predictors of Custom Defection and Loyalty}},
 year = {2015}
 }
 
 @article{Burez2009,
 abstract = {Customer churn is often a rare event in service industries, but of great interest and great value. Until recently, however, class imbalance has not received much attention in the        context of data mining [Weiss, G. M. (2004). Mining with rarity: A unifying framework. SIGKDD Explorations, 6(1), 7-19]. In this study, we investigate how we can better handle class imbalance in    churn prediction. Using more appropriate evaluation metrics (AUC, lift), we investigated the increase in performance of sampling (both random and advanced under-sampling) and two specific           modelling techniques (gradient boosting and weighted random forests) compared to some standard modelling techniques. AUC and lift prove to be good evaluation metrics. AUC does not depend on a       threshold, and is therefore a better overall evaluation metric compared to accuracy. Lift is very much related to accuracy, but has the advantage of being well used in marketing practice [Ling,     C., {\&} Li, C. (1998). Data mining for direct marketing problems and solutions. In Proceedings of the fourth international conference on knowledge discovery and data mining (KDD-98). New York,     NY: AAAI Press]. Results show that under-sampling can lead to improved prediction accuracy, especially when evaluated with AUC. Unlike Ling and Li [Ling, C., {\&} Li, C. (1998). Data mining for     direct marketing problems and solutions. In Proceedings of the fourth international conference on knowledge discovery and data mining (KDD-98). New York, NY: AAAI Press], we find that there is no   need to under-sample so that there are as many churners in your training set as non churners. Results show no increase in predictive performance when using the advanced sampling technique CUBE in   this study. This is in line with findings of Japkowicz [Japkowicz, N. (2000). The class imbalance problem: significance and strategies. In Proceedings of the 2000 international conference on        artificial intelligence (IC-AI'2000): Special track on inductive learning, Las Vegas, Nevada], who noted that using sophisticated sampling techniques did not give any clear advantage. Weighted      random forests, as a cost-sensitive learner, performs significantly better compared to random forests, and is therefore advised. It should, however always be compared to logistic regression.        Boosting is a very robust classifier, but never outperforms any other technique. ?? 2008 Elsevier Ltd. All rights reserved.},
 author = {Burez, J. and {Van den Poel}, D.},
 doi = {10.1016/j.eswa.2008.05.027},
 isbn = {0957-4174},
 issn = {09574174},
 journal = {Expert Systems with Applications},
 keywords = {Boosting,CUBE,Class imbalance,Classifier,Customer churn,Oversampling,Random forests,Rare events,Under-sampling},
 number = {3 PART 1},
 pages = {4626--4636},
 publisher = {Elsevier Ltd},
 title = {{Handling class imbalance in customer churn prediction}},
 url = {http://dx.doi.org/10.1016/j.eswa.2008.05.027},
 volume = {36},
 year = {2009}
 }


@article{Ballings2012,
 abstract = {The key question of this study is: How long should customer event history be for customer churn prediction? While most studies in predictive churn modeling aim to improve models by      data augmentation or algorithm improvement, this study focuses on a another dimension: time window optimization with respect to predictive performance. This paper first presents a formalization of  the time window selection strategy, along with a literature review. Next, using logistic regression, classification trees and bagging in combination with classification trees, this study analyzes   the improvement in churn-model performance by extending customer event history from one to sixteen years. The results show that, after the fifth additional year, predictive performance is only      marginally increased, meaning that the company in this study can discard 69{\%} of its data with almost no decrease in predictive performance. The practical implication is that analysts can         substantially decrease data-related burdens, such as data storage, preparation and analysis. This is particularly valuable in times of big data when decreasing computational complexity is           paramount. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
 author = {Ballings, Michel and {Van Den Poel}, Dirk},
 doi = {10.1016/j.eswa.2012.07.006},
 isbn = {0957-4174},
 issn = {09574174},
 journal = {Expert Systems with Applications},
 keywords = {Explanatory period,Independent period,Length of customer event history,Predictive analytics,Predictive customer churn model,Time window},
 number = {18},
 pages = {13517--13522},
 publisher = {Elsevier Ltd},
 title = {{Customer event history for churn prediction: How long is long enough?}},
 url = {http://dx.doi.org/10.1016/j.eswa.2012.07.006},
 volume = {39},
 year = {2012}
 }
