@InProceedings{heisenberg2015,
  author = 	 {Heisenberg, Werner and Dirac, Paul},
  title = 	 {To be or not to be},
  booktitle =    {Proceedings of the Uncertain Society Annual Meeting},
  year = 	 {2015},
  editor = 	 {Schr√∂dinger, Erwin},
  pages =	 {21--22}
}

 @article{Pudipeddi2014,
 author = {Pudipeddi, Jagat and Akoglu, Leman and Tong, Hanghang},
 file = {:home/helder/Downloads/p469-akoglu.pdf:pdf},
 isbn = {9781450327459},
 keywords = {a sites,churn prediction,feature extraction,q,user churn},
 pages = {469--474},
 title = {{User Churn in Focused Question Answering Sites: Characterizations and Prediction}},
 year = {2014}
 }

@article{Wangperawong2016,
 abstract = {Customer temporal behavioral data was represented as images in order to perform churn prediction by leveraging deep learning architectures prominent in image classification. Supervised  learning was performed on labeled data of over 6 million customers using deep convolutional neural networks, which achieved an AUC of 0.743 on the test dataset using no more than 12 temporal        features for each customer. Unsupervised learning was conducted using autoencoders to better understand the reasons for customer churn. Images that maximally activate the hidden units of an         autoencoder trained with churned customers reveal ample opportunities for action to be taken to prevent churn among strong data, no voice users.},
 archivePrefix = {arXiv},
 arxivId = {1604.05377},
 author = {Wangperawong, Artit and Brun, Cyrille and Laudy, Dr. Olav and Pavasuthipaisit, Rujikorn},
 eprint = {1604.05377},
 keywords = {1,2,3,big data,churn and take,churn prediction,cnns,deep learning,deep learning by convolutional,has demonstrated superior performance,images,in many image processing,in order to        leverage,it,machine learning,neural networks,pro-active measures to prevent,specifically,such advances to predict,tasks,telecommunications,we construct a 2-,we represent customers as},
 pages = {1--6},
 title = {{Churn analysis using deep convolutional neural networks and autoencoders}},
 year = {2016}
 }

 @article{Tax2016,
 abstract = {Predictive business process monitoring methods exploit logs of completed cases of a process in order to make predictions about running cases thereof. Existing methods in this space are  tailor-made for specific prediction tasks. Moreover, their relative accuracy is highly sensitive to the dataset at hand, thus requiring users to engage in trial-and-error and tuning when applying   them in a specific setting. This paper investigates Long Short-Term Memory (LSTM) neural networks as an approach to build consistently accurate models for a wide range of predictive process         monitoring tasks. First, we show that LSTMs outperform existing techniques to predict the next event of a running case and its timestamp. Next, we show how to use models for predicting the next     task in order to predict the full continuation of a running case. Finally, we apply the same approach to predict the remaining time, and show that this approach outperforms existing tailor-made     methods.},
 archivePrefix = {arXiv},
 arxivId = {1612.02130},
 author = {Tax, Niek and Verenich, Ilya and {La Rosa}, Marcello and Dumas, Marlon},
 eprint = {1612.02130},
 title = {{Predictive Business Process Monitoring with LSTM Neural Networks}},
 url = {http://arxiv.org/abs/1612.02130},
 year = {2016}
 }
 
@article{Runge2014,
 abstract = {Predicting when players will leave a game creates a unique opportunity to increase players' lifetime and revenue contribution. Players can be incentivized to stay, strategically cross-  linked to other games in the company's portfolio or, as a last resort, be passed on to other companies through in-game advertisement. This paper focuses on predicting churn for highvalue players    of casual social games and attempts to assess the business impact that can be derived from a predictive churn model. We compare the prediction performance of four common classification algorithms   over two casual social games, each with millions of players. Furthermore, we implement a hidden Markov model to explicitly address temporal dynamics. We find that a neural network achieves the      best prediction performance in terms of area under curve (AUC). In addition, to assess the business value of churn prediction, we design and implement an A/B test on one of the games, using free    in-game currency as an incentive to retain players. Test results indicate that contacting players shortly before the predicted churn event substantially improves the effectiveness of communication  with players. They further show that giving out free in-game currency does not significantly impact the churn rate or monetization of players. This suggests that players can only be retained by     remarkably changing their gameplay experience ahead of the churn event and that cross-linking may be the more effective measure to deal with churning players.},
 author = {Runge, Julian and Gao, Peng and Garcin, Florent and Faltings, Boi},
 doi = {10.1109/CIG.2014.6932875},
 isbn = {9781479935468},
 issn = {23254289},
 journal = {IEEE Conference on Computatonal Intelligence and Games, CIG},
 keywords = {A/B evaluation,churn prediction,freemium,hidden Markov model,neural networks,social casual games},
 title = {{Churn prediction for high-value players in casual social games}},
 year = {2014}
 }
 
  @article{Dror2012,
 author = {Dror, Gideon and Pelleg, Dan and Rokhlenko, Oleg and Szpektor, Idan},
 isbn = {9781450312301},
 journal = {Proceedings of the 21st International Conference on World Wide Web},
 keywords = {churn prediction,community question answering,online user},
 pages = {829--834},
 title = {{Churn prediction in new users of Yahoo! answers}},
 year = {2012}
 }

@article{Hassouna2015,
 author = {Hassouna, Mohammed and Tarhini, Ali and Elyas, Tariq and Aboutrab, Mohammad Saeed and Kingdom, United and Kingdom, United and Arabia, Saudi},
 doi = {10.5539/ibr.v8n6p224},
 file = {:home/helder/Downloads/1607.07792.pdf:pdf},
 keywords = {customer churn,customer relationship management,data mining,mobile market},
 number = {6},
 pages = {224--237},
 title = {{Customer Churn in Mobile Markets: A Comparison of Techniques}},
 volume = {8},
 year = {2015}
 }

 @article{Lu2014,
 author = {Lu, Ning and Lin, Hua and Lu, Jie and Zhang, Guangquan},
 doi = {10.1109/TII.2012.2224355},
 issn = {15513203},
 journal = {IEEE Transactions on Industrial Informatics},
 keywords = {Boosting,Telecommunication,churn prediction,customer relationship management,digital marketing,logistic regression},
 number = {2},
 pages = {1659--1665},
 title = {{A customer churn prediction model in telecom industry using boosting}},
 volume = {10},
 year = {2014}
 }
 
  @article{Khan2015,
 abstract = {Churn prediction, or the task of identifying customers who are likely to discontinue use of a service, is an important and lucrative concern of firms in many different industries. As    these firms collect an increasing amount of large-scale, heterogeneous data on the characteristics and behaviors of customers, new methods become possible for predicting churn. In this paper, we    present a unified analytic framework for detecting the early warning signs of churn, and assigning a "Churn Score" to each customer that indicates the likelihood that the particular individual      will churn within a predefined amount of time. This framework employs a brute force approach to feature engineering, then winnows the set of relevant attributes via feature selection, before        feeding the final feature-set into a suite of supervised learning algorithms. Using several terabytes of data from a large mobile phone network, our method identifies several intuitive - and a few  surprising - early warning signs of churn, and our best model predicts whether a subscriber will churn with 89.4{\%} accuracy.},
 author = {Khan, Muhammad Raza and Manoj, Joshua and Singh, Anikate and Blumenstock, Joshua},
 doi = {10.1109/BigDataCongress.2015.107},
 isbn = {9781467372787},
 journal = {Proceedings - 2015 IEEE International Congress on Big Data, BigData Congress 2015},
 keywords = {Churn,call detail records,data science,machine learning,supervised learning},
 pages = {677--680},
 title = {{Behavioral Modeling for Churn Prediction: Early Indicators and Accurate Predictors of Custom Defection and Loyalty}},
 year = {2015}
 }
 
 @article{Burez2009,
 abstract = {Customer churn is often a rare event in service industries, but of great interest and great value. Until recently, however, class imbalance has not received much attention in the        context of data mining [Weiss, G. M. (2004). Mining with rarity: A unifying framework. SIGKDD Explorations, 6(1), 7-19]. In this study, we investigate how we can better handle class imbalance in    churn prediction. Using more appropriate evaluation metrics (AUC, lift), we investigated the increase in performance of sampling (both random and advanced under-sampling) and two specific           modelling techniques (gradient boosting and weighted random forests) compared to some standard modelling techniques. AUC and lift prove to be good evaluation metrics. AUC does not depend on a       threshold, and is therefore a better overall evaluation metric compared to accuracy. Lift is very much related to accuracy, but has the advantage of being well used in marketing practice [Ling,     C., {\&} Li, C. (1998). Data mining for direct marketing problems and solutions. In Proceedings of the fourth international conference on knowledge discovery and data mining (KDD-98). New York,     NY: AAAI Press]. Results show that under-sampling can lead to improved prediction accuracy, especially when evaluated with AUC. Unlike Ling and Li [Ling, C., {\&} Li, C. (1998). Data mining for     direct marketing problems and solutions. In Proceedings of the fourth international conference on knowledge discovery and data mining (KDD-98). New York, NY: AAAI Press], we find that there is no   need to under-sample so that there are as many churners in your training set as non churners. Results show no increase in predictive performance when using the advanced sampling technique CUBE in   this study. This is in line with findings of Japkowicz [Japkowicz, N. (2000). The class imbalance problem: significance and strategies. In Proceedings of the 2000 international conference on        artificial intelligence (IC-AI'2000): Special track on inductive learning, Las Vegas, Nevada], who noted that using sophisticated sampling techniques did not give any clear advantage. Weighted      random forests, as a cost-sensitive learner, performs significantly better compared to random forests, and is therefore advised. It should, however always be compared to logistic regression.        Boosting is a very robust classifier, but never outperforms any other technique. ?? 2008 Elsevier Ltd. All rights reserved.},
 author = {Burez, J. and {Van den Poel}, D.},
 doi = {10.1016/j.eswa.2008.05.027},
 isbn = {0957-4174},
 issn = {09574174},
 journal = {Expert Systems with Applications},
 keywords = {Boosting,CUBE,Class imbalance,Classifier,Customer churn,Oversampling,Random forests,Rare events,Under-sampling},
 number = {3 PART 1},
 pages = {4626--4636},
 publisher = {Elsevier Ltd},
 title = {{Handling class imbalance in customer churn prediction}},
 url = {http://dx.doi.org/10.1016/j.eswa.2008.05.027},
 volume = {36},
 year = {2009}
 }


@article{Ballings2012,
 abstract = {The key question of this study is: How long should customer event history be for customer churn prediction? While most studies in predictive churn modeling aim to improve models by      data augmentation or algorithm improvement, this study focuses on a another dimension: time window optimization with respect to predictive performance. This paper first presents a formalization of  the time window selection strategy, along with a literature review. Next, using logistic regression, classification trees and bagging in combination with classification trees, this study analyzes   the improvement in churn-model performance by extending customer event history from one to sixteen years. The results show that, after the fifth additional year, predictive performance is only      marginally increased, meaning that the company in this study can discard 69{\%} of its data with almost no decrease in predictive performance. The practical implication is that analysts can         substantially decrease data-related burdens, such as data storage, preparation and analysis. This is particularly valuable in times of big data when decreasing computational complexity is           paramount. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
 author = {Ballings, Michel and {Van Den Poel}, Dirk},
 doi = {10.1016/j.eswa.2012.07.006},
 isbn = {0957-4174},
 issn = {09574174},
 journal = {Expert Systems with Applications},
 keywords = {Explanatory period,Independent period,Length of customer event history,Predictive analytics,Predictive customer churn model,Time window},
 number = {18},
 pages = {13517--13522},
 publisher = {Elsevier Ltd},
 title = {{Customer event history for churn prediction: How long is long enough?}},
 url = {http://dx.doi.org/10.1016/j.eswa.2012.07.006},
 volume = {39},
 year = {2012}
 }

@article{Borbora2011,
 abstract = {In this paper, we investigate the problem of churn prediction in Massively multiplayer online role-playing games (MMORPGs) from a social science perspective and develop models           incorporating theories of player motivation. The ability to predict player churn can be a valuable resource to game developers designing customer retention strategies. The results from our theory-  driven model significantly outperform a diffusion-based churn prediction model on the same dataset. We describe the synthesis between a theory-driven approach and a data-driven approach to a        problem and examine the trade-offs involved between the two approaches in terms of prediction accuracy, interpretability and model complexity. We observe that even though the theory-driven model    is not as accurate as the data-driven one, the theory-driven model itself can be more interpretable to the domain experts and hence, more preferable over a complex data-driven model. We perform     lift analysis of the two models and find that if a marketing effort is restricted in the number of customers it can contact, the theory-driven model would offer much better return-on-investment by  identifying more customers among that restricted set who have the highest probability of churn. Finally, we use a clustering technique to partition the dataset and then build an ensemble on the     partitioned dataset for better performance. Experiment results show that the ensemble performs notably better than the single classifier in terms of its recall value, which is a highly desirable    property in the churn prediction problem.},
 author = {Borbora, Zoheb and Srivastava, Jaideep and Hsu, Kuo Wei and Iams, Dmitri Wil},
 doi = {10.1109/PASSAT/SocialCom.2011.122},
 isbn = {9780769545783},
 journal = {Proceedings - 2011 IEEE International Conference on Privacy, Security, Risk and Trust and IEEE International Conference on Social Computing, PASSAT/SocialCom 2011},
 pages = {157--164},
 title = {{Churn prediction in MMORPGs using player motivation theories and an ensemble approach}},
 year = {2011}
 }

@article{Zhang2013,
 abstract = {Spotify is a peer-assisted music streaming service that has gained worldwide popularity in the past few years. Until now, little has been published about user behavior in such           services. In this paper, we study the user behavior in Spotify by analyzing a massive dataset collected between 2010 and 2011. Firstly, we investigate the system dynamics including session arrival  patterns, playback arrival patterns, and daily variation of session length. Secondly, we analyze individual user behavior on both multiple and single devices. Our analysis reveals the favorite      times of day for Spotify users. We also show the correlations between both the length and the downtime of successive user sessions on single devices. In particular, we conduct the first analysis    of the device-switching behavior of a massive user base.},
 author = {Zhang, Boxun and Kreitz, Gunnar and Isaksson, Marcus and Ubillos, Javier and Urdaneta, Guido and Pouwelse, Johan a. and Epema, Dick},
 doi = {10.1109/INFCOM.2013.6566767},
 isbn = {978-1-4673-5946-7},
 issn = {0743-166X},
 journal = {2013 Proceedings IEEE INFOCOM},
 keywords = {Correlation,Mobile communication,Mobile computing,Mobile handsets,Music,Spotify,Streaming media,Switches,behavioural sciences computing,collected dataset analysis,device switching       behavior,massive user base,media streaming,peer assisted music streaming service,peer-to-peer computing,playback arrival pattern,session arrival pattern,successive user session,user behavior},
 pages = {220--224},
 title = {{Understanding user behavior in Spotify}},
 url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6566767},
 year = {2013}
 }
 
@article{Langkvist2014,
 abstract = {This paper gives a review of the recent developments in deep learning and unsupervised feature learning for time-series problems. While these techniques have shown promise for modeling  static data, such as computer vision, applying them to time-series data is gaining increasing attention. This paper overviews the particular challenges present in time-series data and provides a    review of the works that have either applied time-series data to unsupervised feature learning algorithms or alternatively have contributed to modifications of feature learning algorithms to take   into account the challenges present in time-series data. ?? 2014 Elsevier Ltd.},
 author = {L√§ngkvist, Martin and Karlsson, Lars and Loutfi, Amy},
 doi = {10.1016/j.patrec.2014.01.008},
 isbn = {0167-8655},
 issn = {01678655},
 journal = {Pattern Recognition Letters},
 keywords = {Deep learning,Time-series,Unsupervised feature learning},
 number = {1},
 pages = {11--24},
 title = {{A review of unsupervised feature learning and deep learning for time-series modeling}}, 
 volume = {42},
 year = {2014} 
 }
 
  @article{GurAli2014,
 abstract = {Customer churn prediction literature has been limited to modeling churn in the next (feasible) time period. On the other hand, lead time specific churn predictions can help businesses   to allocate retention efforts across time, as well as customers, and identify early triggers and indicators of customer churn. We propose a dynamic churn prediction framework for generating         training data from customer records, and leverage it for predicting customer churn within multiple horizons using standard classifiers. Further, we empirically evaluate the proposed approach in a   case study about private banking customers in a European bank. The proposed framework includes customer observations from different time periods, and thus addresses the absolute rarity issue that   is relevant for the most valuable customer segment of many companies. It also increases the sampling density in the training data and allows the models to generalize across behaviors in different   time periods while incorporating the impact of the environmental drivers. As a result, this framework significantly increases the prediction accuracy across prediction horizons compared to the      standard approach of one observation per customer; even when the standard approach is modified with oversampling to balance the data, or lags of customer behavior features are added as additional   predictors. The proposed approach to dynamic churn prediction involves a set of independently trained horizon-specific binary classifiers that use the proposed dataset generation framework. In the  absence of predictive dynamic churn models, we had to benchmark survival analysis which is used predominantly as a descriptive tool. The proposed method outperforms survival analysis in terms of    predictive accuracy for all lead times, with a much lower variability. Further, unlike Cox regression, it provides horizon specific ranking of customers in terms of churn probability which allows   allocation of retention efforts across customers and time periods. {\textcopyright} 2014 Elsevier Ltd. All rights reserved.},
 author = {{G{\"{u}}r Ali}, {\"{O}}zden and Arit{\"{u}}rk, Umut},
 doi = {10.1016/j.eswa.2014.06.018},
 issn = {09574174},
 journal = {Expert Systems with Applications},
 keywords = {Customer relationship management,Customer retention,Data mining,Dynamic churn prediction,Private banking,Rare event,Sampling,Training data generation},
 number = {17},
 pages = {7889--7903},
 title = {{Dynamic churn prediction framework with more effective use of rare event data: The case of private banking}},
 volume = {41},
 year = {2014}
 }

 @article{Auon2015,
 abstract = {See, stats, and : https : / / www . researchgate . net / publication / 292972291 Deep Conference CITATIONS 0 READS 268 6 , including : Auon Tata 2 SEE Pankaj Tata 9 SEE Puneet Tata 26   SEE Gautam Tata 48 SEE All - text , letting . Available : Auon Retrieved : 30 Abstract Consumer brands often run promotional campaigns and offer discounts / coupons to attract new customers . To    increase the loyal customer base and enhance re - turn on investment (ROI) , it is important for consumer brands to identify the customers who are more likely to return for repeat purchase (s)      after availing an offer . The basket - level transaction history is typically used to predict the repeat - purchase behavior of customers . Different aspects of a customer ' s behavior can be       captured using aggregate information (e . g . , total number of purchases made over last one year) and temporal information (e . g . , time - series of daily or weekly purchases) . Most existing    models either use aggregate level features only or inde - pendent window - based features without considering the sequence of transactions . We propose that a prediction model based on a            combination of temporal and ag - gregate level models performs better compared to individual models . We use Long Short Term Memory (LSTM) as a classifier over temporal features as time - series    and quantile regression (QR) as a classifier over aggregate level features . QR focuses on capturing aggregate level aspects while LSTM focuses on capturing temporal aspects of behavior for         predicting repeating tendencies . The two models are then combined using a mixture of experts (ME) . Experiments on a real - world Kaggle dataset demonstrate significant improvement in performance  in terms of mean squared error (MSE) on using ME . Additionally , we demonstrate that the DFT coefficients of the time - series for repeaters and non - repeaters lie in separate low - dimensional   embeddings indicating that there is a prominent discriminative signal in the temporal data .},
 author = {Auon, Gaurangi Anand and Kazmi, Haidar and Malhotra, Pankaj and Vig, Lovekesh and Agarwal, Puneet and Shroff, Gautam},
 number = {February 2016},
 title = {{Deep Temporal Features to Predict Repeat Buyers}},
 year = {2015}
 }

@inproceedings{graves2013speech,
  title={Speech recognition with deep recurrent neural networks},
  author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  booktitle={Acoustics, speech and signal processing (icassp), 2013 ieee international conference on},
  pages={6645--6649},
  year={2013},
  organization={IEEE}
}

@inproceedings{yue2015beyond,
  title={Beyond short snippets: Deep networks for video classification},
  author={Yue-Hei Ng, Joe and Hausknecht, Matthew and Vijayanarasimhan, Sudheendra and Vinyals, Oriol and Monga, Rajat and Toderici, George},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4694--4702},
  year={2015}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@article{lazarov2007churn,
  title={Churn prediction},
  author={Lazarov, Vladislav and Capota, Marius},
  journal={Bus. Anal. Course. TUM Comput. Sci},
  year={2007},
  publisher={Citeseer}
}

@article{Drachen2016RapidPO,
  title={Rapid Prediction of Player Retention in Free-to-Play Mobile Games},
  author={Anders Drachen and Eric Thurston Lundquist and Yungjen Kung and Pranav Simha Rao and Diego Klabjan and Rafet Sifa and Julian Runge},
  journal={CoRR},
  year={2016},
  volume={abs/1607.03202}
}

@article{coussement2008churn,
  title={Churn prediction in subscription services: An application of support vector machines while comparing two parameter-selection techniques},
  author={Coussement, Kristof and Van den Poel, Dirk},
  journal={Expert systems with applications},
  volume={34},
  number={1},
  pages={313--327},
  year={2008},
  publisher={Elsevier}
}

@article{mahajan2015review,
  title={Review of data mining techniques for churn prediction in telecom},
  author={Mahajan, Vishal and Misra, Richa and Mahajan, Renuka},
  journal={Journal of Information and Organizational Sciences},
  volume={39},
  number={2},
  pages={183--197},
  year={2015},
  publisher={Fakultet organizacije i informatike Sveu{\v{c}}ili{\v{s}}ta u Zagrebu}
}

@article{powers2011evaluation,
  title={Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation},
  author={Powers, David Martin},
  year={2011},
  publisher={Bioinfo Publications}
}

@article{guyon2003introduction,
  title={An introduction to variable and feature selection},
  author={Guyon, Isabelle and Elisseeff, Andr{\'e}},
  journal={Journal of machine learning research},
  volume={3},
  number={Mar},
  pages={1157--1182},
  year={2003}
}

@misc{netflixsh,
  title = {{Netflix Quarterly Earnings}},
  howpublished = {https://ir.netflix.com/results.cfm},
  note = {Acessed: 2017-03-01}
}

@misc{spotifypress,
  title = {{Spotify Press}},
  howpublished = {https://press.spotify.com/us/about/},
  note = {Accessed: 2017-03-01}
}

@misc{ifpi,
  title = {{IFPI Global Music Report 2016}},
  howpublished = {http://www.ifpi.org/downloads/GMR2016.pdf},
  note = {Accessed: 2017-03-01}
}

@article{walker1967estimation,
  title={Estimation of the probability of an event as a function of several independent variables},
  author={Walker, Strother H and Duncan, David B},
  journal={Biometrika},
  volume={54},
  number={1-2},
  pages={167--179},
  year={1967},
  publisher={Biometrika Trust}
}

@article{cox1958regression,
  title={The regression analysis of binary sequences},
  author={Cox, David R},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={215--242},
  year={1958},
  publisher={JSTOR}
}

@incollection{lecun2012efficient,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@inproceedings{ling1998data,
  title={Data mining for direct marketing: Problems and solutions.},
  author={Ling, Charles X and Li, Chenghui},
  booktitle={KDD},
  volume={98},
  pages={73--79},
  year={1998}
}

@article{sato2012inside,
  title={An inside look at google bigquery},
  author={Sato, Kazunori},
  journal={White paper, URL: https://cloud. google. com/files/BigQueryTechnicalWP. pdf},
  year={2012}
}

@article{hotelling1933analysis,
  title={Analysis of a complex of statistical variables into principal components.},
  author={Hotelling, Harold},
  journal={Journal of educational psychology},
  volume={24},
  number={6},
  pages={417},
  year={1933},
  publisher={Warwick \& York}
}

@inproceedings{larochelle2007empirical,
  title={An empirical evaluation of deep architectures on problems with many factors of variation},
  author={Larochelle, Hugo and Erhan, Dumitru and Courville, Aaron and Bergstra, James and Bengio, Yoshua},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={473--480},
  year={2007},
  organization={ACM}
}

@article{bergstra2012random,
  title={Random search for hyper-parameter optimization},
  author={Bergstra, James and Bengio, Yoshua},
  journal={Journal of Machine Learning Research},
  volume={13},
  number={Feb},
  pages={281--305},
  year={2012}
}

@article{cawley2010over,
  title={On over-fitting in model selection and subsequent selection bias in performance evaluation},
  author={Cawley, Gavin C and Talbot, Nicola LC},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Jul},
  pages={2079--2107},
  year={2010}
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{coussement2013customer,
  title={Customer churn prediction in the online gambling industry: The beneficial effect of ensemble learning},
  author={Coussement, Kristof and De Bock, Koen W},
  journal={Journal of Business Research},
  volume={66},
  number={9},
  pages={1629--1636},
  year={2013},
  publisher={Elsevier}
}

@article{burez2008separating,
  title={Separating financial from commercial customer churn: A modeling step towards resolving the conflict between the sales and credit department},
  author={Burez, Jonathan and Van den Poel, Dirk},
  journal={Expert Systems with Applications},
  volume={35},
  number={1},
  pages={497--514},
  year={2008},
  publisher={Elsevier}
}

@book{breiman1984classification,
  title={Classification and regression trees},
  author={Breiman, Leo and Friedman, Jerome and Stone, Charles J and Olshen, Richard A},
  year={1984},
  publisher={CRC press}
}

@article{werbos1990backpropagation,
  title={Backpropagation through time: what it does and how to do it},
  author={Werbos, Paul J},
  journal={Proceedings of the IEEE},
  volume={78},
  number={10},
  pages={1550--1560},
  year={1990},
  publisher={IEEE}
}

@article{bengio1994learning,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}

@misc{hochreiter2001gradient,
  title={Gradient flow in recurrent nets: the difficulty of learning long-term dependencies},
  author={Hochreiter, Sepp and Bengio, Yoshua and Frasconi, Paolo and Schmidhuber, J{\"u}rgen and others},
  year={2001},
  publisher={A field guide to dynamical recurrent neural networks. IEEE Press}
}

@article{williams1989learning,
  title={A learning algorithm for continually running fully recurrent neural networks},
  author={Williams, Ronald J and Zipser, David},
  journal={Neural computation},
  volume={1},
  number={2},
  pages={270--280},
  year={1989},
  publisher={MIT Press}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{gers1999learning,
  title={Learning to forget: Continual prediction with LSTM},
  author={Gers, Felix A and Schmidhuber, J{\"u}rgen and Cummins, Fred},
  year={1999},
  publisher={IET}
}

@article{zaremba2014learning,
  title={Learning to execute},
  author={Zaremba, Wojciech and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1410.4615},
  year={2014}
}

@inproceedings{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={3104--3112},
  year={2014}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

@article{zeiler2012adadelta,
  title={ADADELTA: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}

@article{pearson1901liii,
  title={LIII. On lines and planes of closest fit to systems of points in space},
  author={Pearson, Karl},
  journal={The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume={2},
  number={11},
  pages={559--572},
  year={1901},
  publisher={Taylor \& Francis}
}

@article{lema2017imbalanced,
author  = {Guillaume  Lema{{\^i}}tre and Fernando Nogueira and Christos K. Aridas},
title   = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
journal = {Journal of Machine Learning Research},
year    = {2017},
volume  = {18},
number  = {17},	
pages   = {1-5},
url     = {http://jmlr.org/papers/v18/16-365.html}
}

@misc{scio,
  author = {Spotify},
  title = {{Scio: A Scala API for Apache Beam and Google Cloud Dataflow}},
  howpublished = "\url{http://spotify.github.io/scio}",
  year = {2015}, 
  note = "[Online; accessed 01-July-2017]"
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  publisher={GitHub},
  howpublished={\url{https://github.com/fchollet/keras}},
  note = "[Online; accessed 01-July-2017]"
}

@article{abadi2016tensorflow,
  title={Tensorflow: Large-scale machine learning on heterogeneous distributed systems},
  author={Abadi, Mart{\'\i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and others},
  journal={arXiv preprint arXiv:1603.04467},
  year={2016}
}

@article{stone1974cross,
  title={Cross-validatory choice and assessment of statistical predictions},
  author={Stone, Mervyn},
  journal={Journal of the royal statistical society. Series B (Methodological)},
  pages={111--147},
  year={1974},
  publisher={JSTOR}
}

@article{adams1995hitchhikers,
  added-at = {2012-01-27T14:41:50.000+0100},
  author = {Adams, Douglas},
  biburl = {https://www.bibsonomy.org/bibtex/2e170eb13993a56f57e814c7537caa316/nosebrain},
  interhash = {2689edbe3de2f39388b4d16880b7fbe9},
  intrahash = {e170eb13993a56f57e814c7537caa316},
  keywords = {galaxy guide hitchhiker scifi},
  timestamp = {2013-06-25T18:26:30.000+0200},
  title = {The Hitchhiker's Guide to the Galaxy},
  year = 1995
}

@inproceedings{bulucc2009parallel,
  title={Parallel sparse matrix-vector and matrix-transpose-vector multiplication using compressed sparse blocks},
  author={Bulu{\c{c}}, Aydin and Fineman, Jeremy T and Frigo, Matteo and Gilbert, John R and Leiserson, Charles E},
  booktitle={Proceedings of the twenty-first annual symposium on Parallelism in algorithms and architectures},
  pages={233--244},
  year={2009},
  organization={ACM}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
  pages={249--256},
  year={2010}
}

@article{saxe2013exact,
  title={Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
  author={Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
  journal={arXiv preprint arXiv:1312.6120},
  year={2013}
}

@misc{hinton2012rmsprop,
  title={Neural Networks for Machine Learning},
  author={Hinton, Geoffrey},
  year={2012},
  publisher={Toronto University},
  howpublished={\url{http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf}},
  note = "[Online; accessed 01-July-2017]"
}

@inproceedings{phaisangittisagul2016analysis,
  title={An Analysis of the Regularization Between L2 and Dropout in Single Hidden Layer Neural Network},
  author={Phaisangittisagul, Ekachai},
  booktitle={Intelligent Systems, Modelling and Simulation (ISMS), 2016 7th International Conference on},
  pages={174--179},
  year={2016},
  organization={IEEE}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting.},
  author={Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014}
}

@article{zaremba2014recurrent,
  title={Recurrent neural network regularization},
  author={Zaremba, Wojciech and Sutskever, Ilya and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1409.2329},
  year={2014}
}

@article{domingos2012few,
  title={A few useful things to know about machine learning},
  author={Domingos, Pedro},
  journal={Communications of the ACM},
  volume={55},
  number={10},
  pages={78--87},
  year={2012},
  publisher={ACM}
}

@article{kramer2014experimental,
  title={Experimental evidence of massive-scale emotional contagion through social networks},
  author={Kramer, Adam DI and Guillory, Jamie E and Hancock, Jeffrey T},
  journal={Proceedings of the National Academy of Sciences},
  volume={111},
  number={24},
  pages={8788--8790},
  year={2014},
  publisher={National Acad Sciences}
}

@inproceedings{bennett2007netflix,
  title={The Netflix Prize},
  author={Bennett, James and Lanning, Stan and others},
  booktitle={Proceedings of KDD cup and workshop},
  volume={2007},
  pages={35},
  year={2007},
  organization={New York, NY, USA}
}

@misc{wired2010netflix,
  title = {{NetFlix Cancels Recommendation Contest After Privacy Lawsuit}},
  howpublished = {https://www.wired.com/2010/03/netflix-cancels-contest/},
  note = {Accessed: 2017-07-01}
}

@misc{eu2017protection,
  title = {{Protection of personal data}},
  howpublished = {http://ec.europa.eu/justice/data-protection/},
  note = {Accessed: 2017-07-01}
}

@misc{google2017renew,
  title = {{100\% renewable is just the beginning}},
  howpublished = {https://environment.google/projects/announcement-100/},
  note = {Accessed: 2017-07-01}
}

@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@book{ibrahim2005bayesian,
  title={Bayesian survival analysis},
  author={Ibrahim, Joseph G and Chen, Ming-Hui and Sinha, Debajyoti},
  year={2005},
  publisher={Wiley Online Library}
}

@inproceedings{dean2012large,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Senior, Andrew and Tucker, Paul and Yang, Ke and Le, Quoc V and others},
  booktitle={Advances in neural information processing systems},
  pages={1223--1231},
  year={2012}
}

@article{hennig1997impact,
  title={The impact of customer satisfaction and relationship quality on customer retention: A critical reassessment and model development},
  author={Hennig-Thurau, Thorsten and Klee, Alexander},
  journal={Psychology \& marketing},
  volume={14},
  number={8},
  pages={737--764},
  year={1997},
  publisher={Wiley Online Library}
}

@article{morgan2006value,
  title={The value of different customer satisfaction and loyalty metrics in predicting business performance},
  author={Morgan, Neil A and Rego, Lopo Leotte},
  journal={Marketing Science},
  volume={25},
  number={5},
  pages={426--439},
  year={2006},
  publisher={INFORMS}
}

@article{fawcett2004roc,
  title={ROC graphs: Notes and practical considerations for researchers},
  author={Fawcett, Tom},
  journal={Machine learning},
  volume={31},
  number={1},
  pages={1--38},
  year={2004}
}

@article{saito2015precision,
  title={The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets},
  author={Saito, Takaya and Rehmsmeier, Marc},
  journal={PloS one},
  volume={10},
  number={3},
  pages={e0118432},
  year={2015},
  publisher={Public Library of Science}
}

@article{tomek1976two,
  title={Two modifications of CNN},
  author={Tomek, Ivan},
  journal={IEEE Trans. Systems, Man and Cybernetics},
  volume={6},
  pages={769--772},
  year={1976}
}

@article{smith2014instance,
  title={An instance level analysis of data complexity},
  author={Smith, Michael R and Martinez, Tony and Giraud-Carrier, Christophe},
  journal={Machine learning},
  volume={95},
  number={2},
  pages={225--256},
  year={2014},
  publisher={Springer}
}

@inproceedings{chen2016xgboost,
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
  pages={785--794},
  year={2016},
  organization={ACM}
}

